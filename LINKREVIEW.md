# LinkReview

- Here we collect all the works that may be useful for writing our paper
- We divide these works by topic in order to structure them

> [!NOTE]
> This review table will be updated, so it is not a final version.

| Topic | Title | Year | Authors | Paper | Code | Summary |
| :--- | :--- | :---: | :--- | :---: | :---: | :--- |
| Edge of Stability(экспериментальное получение эффекта) | Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability | 2021 | Cohen et al. | [arXiv](https://openreview.net/pdf?id=jh-rTtvkGeM) | [GitHub](https://github.com/locuslab/edge-of-stability) | Эмпирически показывают, что при обучении нейросетей полносвязным градиентным спуском динамика обычно выходит в режим Edge of Stability, где максимальное собственное значение гессиана($\lambda_{max}$) держится чуть выше порога $\frac{2}{\eta}$, loss ведёт себя немонотонно на коротких масштабах, но убывает на длинных; это показывает, что классическая теория далеко не польностью описывает процесс оптимизации(а именно то, что система обычно входит в EoS) и указывает на необходимость новой теории оптимизации для нейросетей, чтобы можно было более оптимально подбирать шаг, опираясь только на теорию. |
| Simplex projection  / EDM | Nonlinear forecasting as a way of distinguishing chaos from measurement error in time series | 1990 | Sugihara G., May R.M. | [Nature 344:734-741](https://www.nature.com/articles/344734a0) | [GitHub](https://github.com/SugiharaLab/pyEDM) | Вводит simplex projection для различения детерминированного хаоса от шума/измерительных ошибок через нелинейное краткосрочное прогнозирование. Анализ кривой предсказуемости ρ(τ) на реальных данных. |
| S-maps / EDM / Time Series Classification | Nonlinear Forecasting for the Classification of Natural Time Series | 1994 | Sugihara G. | [PDF](https://royalsocietypublishing.org/rsta/article-abstract/348/1688/477/113545/Nonlinear-forecasting-for-the-classification-of?redirectedFrom=fulltext) | [GitHub](https://github.com/SugiharaLab/pyEDM) | Вводит метод S-maps для выявления нелинейности в зашумленных данных. Автор критикует расчет показателей Ляпунова для природных рядов из-за влияния динамического шума («стохастический хаос»). Метод использует параметр $\theta$: сравнение точности глобальной линейной модели ($\theta = 0$) и локальной нелинейной ($\theta > 0$) позволяет статистически выявлять и доказывать нелинейность. Также метод помогает отличить системы, в которых все данные это шум, от динамически сложных систем. На данных ЭКГ показано, что старение и болезни сердца коррелируют с потерей нелинейной динамики, что делает метод эффективным инструментом классификации. |
| CCM / Causal Inference / EDM | Detecting Causality in Complex Ecosystems | 2012 | Sugihara et al. | [Science](https://www.science.org/doi/10.1126/science.1227079) | [GitHub](https://github.com/SugiharaLab/pyEDM) | Вводят Convergent Cross Mapping (CCM) для выявления нелинейной причинности в динамических системах черех временные ряды и реконструкцию аттракторов (Теорема Такенса). Конвергенция ρ(L) при росте sizeLibrary L отличает реальные связи от ложных корреляций. Показывают двусторонние связи (хищник-жертва Paramecium-Didinium), одностороннее влияние (SST→сардины/анчоусы) и отличают общий драйвер от конкуренции. Превосходит Granger causality в нелинейных системах с слабой связью, а также в системах где есть драйвер. |
| PCM / Causal Inference / EDM | Partial cross mapping eliminates indirect causal influences | 2020 | Leng et al. | [Nature Communications](https://www.nature.com/articles/s41467-020-16238-0) | [GitHub](https://github.com/Partial-Cross-Mapping) | Предлагают Partial Cross Mapping (PCM) — надстройку над CCM для различения прямых и косвенных причинных связей в нелинейных несепарабельных системах. Метод комбинирует реконструкцию фазового пространства (теорема Такенса(для систем с шумом и внешним воздействием Старка)), взаимный кросс-маппинг CCM и частную корреляцию: индекс $ρ_D = |Pcc(X, \hat{X}^Y | \hat{X}^{\hat{Z}^Y})|$ вычитает косвенный информационный поток через посредника Z из полного причинного сигнала. Решает проблему транзитивности(косвености) причинности, которую CCM не устраняет. Есть рпактические примеры и результаты. Превосходит условную GC и частную TE в несепарабельных системах. |
| Delay Embedding / Takens Theorem | Detecting strange attractors in turbulence | 1981 | Takens F. | [Springer](https://link.springer.com/chapter/10.1007/BFb0091924) | — | Доказывает теорему о вложении с запаздыванием: по скалярному временному ряду одного наблюдения $\phi(x_t)$ можно реконструировать аттрактор исходной динамической системы, построив векторы $(\phi(x_t), \phi(x_{t+\tau}), ..., \phi(x_{t+(d-1)\tau}))$. При $d \geq 2m+1$ ($m$ — размерность аттрактора) такое отображение является диффеоморфизмом для типичных $f$ и $\phi$, то есть реконструированное псевдофазовое пространство топологически эквивалентно исходному. Работа заложила теоретическую основу для нелинейного анализа временных рядов (оценка фрактальной размерности, показателей Ляпунова, предсказание). |
| Delay Embedding / Forced Systems | Delay Embeddings for Forced Systems. I. Deterministic Forcing | 1999 | Stark J. | [Journal of Nonlinear Science](https://link.springer.com/article/10.1007/s003329900072) | — | Обобщает теорему Такенса на неавтономные системы с детерминированным внешним воздействием: $x_{i+1} = f(x_i, y_i)$, где $y_i$ порождается отдельной детерминированной системой. Доказывает Bundle Delay Embedding Theorem: карта запаздывания остаётся вложением для типичных $f$ и $\phi$ при $d \geq 2m+1$, где $m$ — размерность наблюдаемой системы (без учёта форсинга). Ключевое отличие от классики — вложение индексируется реализацией форсинга $\omega$, а координатное преобразование имеет структуру расслоения. Результат важен для анализа реальных данных, где внешние воздействия неизбежны. |
| Delay Embedding / Forced Systems / Stochastic Noice| Delay Embeddings for Forced Systems. II. Stochastic Forcing | 2003 | Stark J., Broomhead D.S., Davies M.E., Huke J. | [Journal of Nonlinear Science](https://link.springer.com/article/10.1007/s00332-003-0534-4) | — | Обобщает результаты Part I на системы со стохастическим форсингом в рамках теории случайных динамических систем. Центральный результат — Теорема 2.3: если инвариантная мера $\mu_\Omega$ на пространстве реализаций абсолютно непрерывна относительно меры Лебега на цилиндрах длины $d−1$, то при $d \geq 2m+1$ карта запаздывания $\Phi_{f,\phi,\omega}$ является полноценным вложением (диффеоморфизмом на образ) для $\mu_\Omega$-почти всех $\omega$. Дополнительно рассмотрены итерированные системы функций (Теорема 2.4, вложение для всех $\omega$) и зашумлённые наблюдения (Теоремы 2.5–2.6). Условие абсолютной непрерывности меры выполнено для большинства стандартных процессов (гауссовский, равномерный шум). |
| Grokking (открытие феномена) | Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets | 2022 | Power et al. | [arXiv](https://arxiv.org/abs/2201.02177) | [GitHub](https://github.com/openai/grok) | Открывают феномен гроккинга: при обучении малого декодерного трансформера (2 слоя, 128 размерность, 4 головы) на алгоритмических задачах вида $a \circ b \pmod{p}$ (модульная арифметика, перестановки $S_5$) модель сначала быстро ($10^3$ шагов) запоминает обучающую выборку, после чего валидационная точность долго остаётся около нуля, и лишь спустя на порядки большее число шагов ($10^6$) внезапно обобщается до 100%. Ключевые находки: (1) время до обобщения растёт по степенному закону $t_4(r) \propto r^{-\gamma}$ при уменьшении доли обучающих данных $r$; (2) weight decay — наиболее эффективное вмешательство, более чем вдвое сокращающее нужный объём данных; (3) любой шум в оптимизации (минибатчи, гауссов шум) полезен; (4) обученные сети обнаруживают реальную алгебраическую структуру в эмбеддингах — круговую топологию для модульного сложения и структуру смежных классов для $S_5$; (5) корреляция Спирмена между пологостью минимума ($\phi$-мера Кескара) и валидационной точностью равна $-0.795$ ($p < 0.000014$), что указывает на связь гроккинга с пологими минимумами. |
| Grokking (предсказание феномена) | Predicting Grokking Long Before it Happens: A look into the loss landscape of models which grok | 2023 | Notsawo et al. | [arXiv](https://arxiv.org/abs/2306.13253) | [GitHub](https://github.com/neelnanda-io/Grokking) | Предлагают дешёвый метод предсказания гроккинга по первым ~400 шагам обучения без ожидания его фактического наступления. Центральная идея: кривые обучения моделей, которые гроккают, демонстрируют характерные осцилляции (связанные со slingshot-эффектом Thilak et al. 2022), и их можно уловить через **спектральную сигнатуру** — параметры Йорта (Hjorth activity $m_0(L) = \int L^2(t)dt$, mobility $\sqrt{m_2/m_0}$, complexity $\sqrt{m_4/m_2}$), напрямую связанные с нормой градиента и спектром гессиана: $\dot{L} \approx -\|G(t)\|^2$, $\ddot{L} \approx 2\sum_i \lambda_i \langle G, v_i\rangle^2$. Паттерн спектральной активности за первые 400 шагов при 70 комбинациях гиперпараметров воспроизводит паттерн итоговой валидационной точности после 10 000 шагов. Анализ ландшафта потерь (1D-проекции методом Li et al. 2018 с filter-wise нормализацией) показывает: (1) существуют два минимума обучающей потери, но только один минимизирует также и валидационную — в фазе запоминания модель застряёт в «плохом»; (2) более 98% дисперсии траектории оптимизации объясняется первыми двумя PCA-компонентами, то есть динамика фактически двумерна; (3) модель большую часть времени работает в режиме lazy training (косинусное расстояние между соседними весами почти константно), за исключением точек слингшота; (4) $\lambda_{min}$ гессиана уходит в отрицательную область только в точках слингшота, нарушая strict saddle property и порождая EoS-поведение ($\lambda_{max} > 2/\varepsilon$). Время обобщения подчиняется степенному закону $t_4(r) = ar^{-\gamma} + b$ (для модульного сложения $\gamma \approx 7.73$). |
